# 1-3_LLM의 구축 단계
## 개념 정리
LLM을 개발하는 일반적인 과정은 사전 훈련과 미세 튜닝으로 구성
- 사전 훈련   
LLM과 같은 모델을 다양한 대규모 데이터셋에서 훈련시켜 언어에 대한 폭넓은 이해를 쌓는 초기 단계를 의미   
LLM의 초기 훈련 단계를 사전훈련(pretraining)이라고 부르며 이렇게 만들어진 사전 훈련된 LLM을 베이스 모델 또는 파운데이션 모델이라고 부름   
이런 모델의 대표적인 예는 GPT-3  

- 미세 튜닝   
모델을 구체적인 작업이나 도메인을 위한 특정 데이터셋에서 훈련하는 과정

## 훈련 방식
1. 레이블이 없는 원시 텍스트(수조 개의 단어)   
	- 예시
		- 인터넷 텍스트   
		- 책   
		- 위키백과   
		- 연구 논문   
	- 설명   
	: LLM을 레이블이 없는 텍스트 데이터에서 사전 훈련한다.

2. 사전 훈련된 LLM(파운데이션 모델)

3. 레이블이 있는 데이터셋
	- 설명   
	사전 훈련된 LLM을 레이블이 있는 데이터셋에서 추가로 훈련하여 특정 작업에 맞게 미세 튜닝된 LLM을 얻음  

4. 미세 튜닝된 LLM
	- 예시
		- 분류   
		- 요약   
		- 번역   
		- 개인 비서   

5. 결과
	- 텍스트 완성   
	- 퓨-샷 학습
	- 사전 훈련 후에 LLM은 몇 가지 기본적인 능력을 가짐


# 1-4_트랜스포머-구조

1. 입력 텍스트   
	번역할 텍스트 입력   
2. 전처리 단계   
	인코더를 위해 입력 텍스트를 전처리   

3. 인코더   
	인코더는 입력 텍스트 전체를 참조하여 디코더에서 사용할 텍스트 임베딩을 생성   

4. 임베딩   
	인코더는 디코더의 입력으로사용될 임베딩을 반환   

5. 입력 텍스트   
	출력 텍스트의 일부 : 모델은 한 번에 한 단어씩 번역을 완성   

6. 전처리 단계   
	디코더를 위해 입력 텍스트를 전처리   

7. 디코더   
	디코더는 한 번에 한 단어씩 번역된 텍스트를 생성   

8. 출력층
	완성된 출력(번역)   


   

